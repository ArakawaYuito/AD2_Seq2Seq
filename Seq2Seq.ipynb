{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c61cc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4379722071988583916\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7798259712\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15486590616004280461\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18053114016940928543\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7798259712\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5160612226288894781\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from encdec_ad_tensorflow.plots import plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import precision_score\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import pickle\n",
    "import metric_learn\n",
    "from sklearn.decomposition import PCA  \n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from encdec_ad_tensorflow.model import EncoderDecoder\n",
    "from sklearn.metrics import fbeta_score\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.client import device_lib; print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "from utils import make_data, make_data_rev, make_label, calc_leq, leq_filter, validate, figure, figure_detail, plot_timeseries, fig_pr, auc_gs, fig_th_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9305103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_to_sequences(x, L, S):\n",
    "    # 長さLのシーケンスをSステップ間隔で取り出していく\n",
    "    # 取り出したシーケンス(特徴量1の場合)の形状は2次元で shape=(L, 1)\n",
    "    # tf.expand_dims(〇, axis=0)により次元を増やして，〇の形状をshape=(1, L, 1)に変形\n",
    "    # tf.concat([], axis=0)で取り出したシーケンスを縦方向に結合して，データセットshape=(None, L, 1)を作る\n",
    "    return tf.concat([tf.expand_dims(x[i - L: i], axis=0) for i in range(L, len(x) + S, S)], axis=0)\n",
    "\n",
    "def sequences_to_time_series(x):\n",
    "    # Transform the sequences back to time series.\n",
    "    # 部分時系列に変換する際にステップをウィンドウサイズにしている必要がある\n",
    "    return tf.reshape(x, (x.shape[0] * x.shape[1], x.shape[2]))\n",
    "\n",
    "\n",
    "def get_anomaly_scores(x, mu, sigma):\n",
    "    # Calculate the anomaly scores.\n",
    "    return tf.map_fn(elems=x, fn=lambda x: tf.squeeze(tf.matmul(tf.matmul(x - mu, tf.linalg.inv(sigma)), x - mu, transpose_b=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f863077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='filtered_csv_label'\n",
    "original = pd.read_csv( os.path.join(data_dir, 'learning_data_10.csv') )\n",
    "df = pd.read_csv( os.path.join(data_dir, 'learning_data_10.csv') )\n",
    "train_df=df[(df['day']!=1)&(df['day']<=5)]\n",
    "test_df=df[df['day']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b6c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df[['original']].values\n",
    "X_test=test_df[['original']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd64a7",
   "metadata": {},
   "source": [
    "## 訓練・検証データ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "980d466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=10     # Number of time steps.\n",
    "step_size=1\n",
    "\n",
    "#  正常な時系列データxn を訓練データと検証データに分ける\n",
    "# x_sn 訓練データセット\n",
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "\n",
    "# 最小値最大値を求めて正規化\n",
    "x_min = tf.reduce_min(X_train, axis=0, keepdims=True)\n",
    "x_max = tf.reduce_max(X_train, axis=0, keepdims=True)\n",
    "# Scale the time series.\n",
    "X_train_sc = (X_train - x_min) / (x_max - x_min)\n",
    "\n",
    "# スライディングウィンドウ\n",
    "x_train = time_series_to_sequences(X_train_sc, L=window_size, S=step_size).numpy()\n",
    "\n",
    "# 訓練データと検証データに分ける\n",
    "x_train, x_valid = train_test_split(x_train, test_size=0.3, random_state=0)\n",
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "x_valid = tf.cast(x_valid, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b41f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, x_train)).shuffle(10000).batch(batch_size)\n",
    "valid_batch_size=2048  \n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, x_valid)).batch(valid_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f82d2a",
   "metadata": {},
   "source": [
    "## テストデータ前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7603a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf.cast(X_test, tf.float32)\n",
    "# Scale the time series.\n",
    "X_test_sc = (X_test- x_min) / (x_max - x_min)\n",
    "\n",
    "# Split the time series into sequences\n",
    "x_test=time_series_to_sequences(X_test_sc, L=window_size, S=step_size)\n",
    "\n",
    "# テストデータセットを作成し、メモリの都合上バッチに分割\n",
    "test_batch = 2048  \n",
    "test_ds = tf.data.Dataset.from_tensor_slices(x_test).batch(test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43776e2c",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42847676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model.\n",
    "c=64      # Number of hidden units.\n",
    "d=0.3     # Dropout rate.\n",
    "learning_rate=0.001\n",
    "early_stopping_patience=10\n",
    "max_epochs=1\n",
    "verbose=1\n",
    "\n",
    "\n",
    "model = EncoderDecoder(\n",
    "    L=window_size,  # input length\n",
    "    m=X_train.shape[-1],  # Number of time series.\n",
    "    c=c,  # hidden size\n",
    "    d=d   # dropout rate\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=tf.keras.losses.MeanSquaredError()\n",
    ")\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=early_stopping_patience,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=max_epochs,\n",
    "    batch_size=128,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580dfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ処理で予測を行う\n",
    "predictions = []\n",
    "for test_x in test_ds:\n",
    "    batch_predictions = model(test_x, training=False)\n",
    "    predictions.extend(batch_predictions.numpy().tolist())\n",
    "\n",
    "predictions=np.array(predictions)\n",
    "error= tf.keras.losses.mae(predictions.reshape(predictions.shape[0], predictions.shape[1]), \n",
    "                       x_test.numpy().reshape(x_test.shape[0], x_test.shape[1])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba5b55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anomary_score=(error-error.min())/(error.max()-error.min())\n",
    "# visualize the error curve\n",
    "plot_timeseries([X_test_sc[:-(window_size-1)].numpy(), predictions[:, 0]], \n",
    "                test_df['label'].values[:-(window_size-1)], anomary_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472559c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa4307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15ccbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf291",
   "language": "python",
   "name": "tf291"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
